{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/home/pleung/projects/bistable_bundle/r3/hinges\n",
      "dig105\n"
     ]
    }
   ],
   "source": [
    "# python internal \n",
    "import collections\n",
    "import copy\n",
    "import gc\n",
    "from glob import glob\n",
    "import h5py\n",
    "import itertools\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import random\n",
    "import re\n",
    "import socket\n",
    "print(socket.gethostname())\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "# conda/pip\n",
    "import dask\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "# special packages on the DIGS\n",
    "import py3Dmol\n",
    "import pymol\n",
    "import pyrosetta\n",
    "# notebook magic\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flo's original approach:\n",
    "7. Two-state design: \n",
    "`/home/flop/switch/5thround/DHRs/msd7/msd_scripts/` has the scripts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I need to add a few things to Flo's method.\n",
    "I will use the serialization build of PyRosetta to enable recording user defined info about the designs.  \n",
    "This enables downstream inline filtering and data analysis, as well as clustering by lineage.\n",
    "\n",
    "TODO sequence recovery of parent as a final metric in 05?  \n",
    "TODO explore `FavorSequenceProfile` instead of `FavorNativeResidue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make functions for looping and labeling to assist downstream penultimate design step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrosetta.distributed.packed_pose.core import PackedPose\n",
    "\n",
    "from typing import *\n",
    "\n",
    "def msd(pickle_str:str, **kwargs) -> Generator[str, PackedPose, None]:\n",
    "    \"\"\"\n",
    "    TODO sc_neighbors?\n",
    "    TODO assumes middle split\n",
    "    \"\"\"\n",
    "    \n",
    "    import binascii\n",
    "    import bz2\n",
    "    from copy import deepcopy\n",
    "    import os\n",
    "    import pickle\n",
    "    import pyrosetta\n",
    "    from pyrosetta.rosetta.core.pose import Pose\n",
    "    import pyrosetta.distributed.io as io\n",
    "    \n",
    "    if pickle_str == None:\n",
    "        pickle_str = kwargs[\"pickle_path\"]\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    with open(pickle_str, \"rb\") as handle:\n",
    "        state_dict = pickle.load(handle)\n",
    "    state_X_dict, state_Y_dict = state_dict[\"state_X_dict\"], state_dict[\"state_Y_dict\"]\n",
    "    \n",
    "    poses = []\n",
    "    # load and set scores of poses for states X and Y\n",
    "    for state in state_X_dict, state_Y_dict:\n",
    "        assert len(state) == 1\n",
    "        (path, scores), = state.items()\n",
    "        with open(path, \"rb\") as f:\n",
    "            filename = str(binascii.b2a_hex(os.urandom(16)).decode(\"utf-8\")) + \".pdb.temp\"\n",
    "            with open(filename, \"w+\") as g:\n",
    "                print(bz2.decompress(f.read()).decode(), file=g)\n",
    "            ppose = io.pose_from_file(filename)\n",
    "            os.remove(filename)\n",
    "            pose = io.to_pose(ppose)\n",
    "            for key, value in scores.items():\n",
    "                pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)\n",
    "        poses.append(pose)\n",
    "    \n",
    "    state_X, state_Y = poses[0], poses[1]\n",
    "    \n",
    "    ala_penalty = 1\n",
    "    if kwargs[\"np_pen\"] == None:\n",
    "        np_penalty = 3\n",
    "    else:\n",
    "        np_penalty = kwargs[\"np_pen\"]\n",
    "    og_np_penalty = deepcopy(np_penalty) # TODO this might be bad\n",
    "    scores = deepcopy(state_Y.scores)\n",
    "    sfxn_used = scores[\"sfxn_used\"]\n",
    "    parent_sequence = state_X.sequence()\n",
    "    # heavily penalize buried unsats, unset lk_ball since it isn't worth using\n",
    "    # setup res_type_constraints for FNR, setup aa_comp, setup SAP constraint\n",
    "    sfxn_obj = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\n",
    "        \"\"\"\n",
    "        <SCOREFXNS>\n",
    "            <ScoreFunction name=\"sfxn\" weights=\"{sfxn_used}\" />\n",
    "            <ScoreFunction name=\"sfxn_design\" weights=\"{sfxn_used}\" >\n",
    "                <Set use_hb_env_dep=\"true\" />\n",
    "                <Reweight scoretype=\"approximate_buried_unsat_penalty\" weight=\"17\" />\n",
    "                <Set approximate_buried_unsat_penalty_burial_atomic_depth=\"3.5\" />\n",
    "                <Set approximate_buried_unsat_penalty_hbond_energy_threshold=\"-1.0\" />\n",
    "                <Set approximate_buried_unsat_penalty_natural_corrections1=\"true\" />\n",
    "                <Set approximate_buried_unsat_penalty_hbond_bonus_cross_chain=\"-7\" />\n",
    "                <Set approximate_buried_unsat_penalty_hbond_bonus_ser_to_helix_bb=\"1\"/>\n",
    "                <Reweight scoretype=\"lk_ball\" weight=\"0\" />\n",
    "                <Reweight scoretype=\"lk_ball_iso\" weight=\"0\" />\n",
    "                <Reweight scoretype=\"lk_ball_bridge\" weight=\"0\" />\n",
    "                <Reweight scoretype=\"lk_ball_bridge_uncpl\" weight=\"0\" />                \n",
    "                \n",
    "                <Reweight scoretype=\"res_type_constraint\" weight=\"2.0\" />\n",
    "                \n",
    "                <Reweight scoretype=\"aa_composition\" weight=\"1.0\" />\n",
    "                \n",
    "                <Reweight scoretype=\"sap_constraint\" weight=\"1.0\" />\n",
    "            </ScoreFunction>\n",
    "        </SCOREFXNS>\n",
    "        \"\"\".format(sfxn_used=sfxn_used)\n",
    "    )\n",
    "\n",
    "    sfxn = sfxn_obj.get_score_function(\"sfxn_design\")\n",
    "    sfxn_clean = sfxn_obj.get_score_function(\"sfxn\")\n",
    "    res = scores[\"total_length\"]\n",
    "    score_per_res_X, score_per_res_Y = sfxn_clean(state_X)/res, sfxn_clean(state_Y)/res\n",
    "    \n",
    "    def yeet_pose_xyz(pose, xyz=(1,0,0)): \n",
    "        \"\"\"\n",
    "        Given a pose and a cartesian 3D unit vector, translates the pose\n",
    "        according to 100 * the unit vector without applying a rotation:\n",
    "        @pleung @bcov @flop\n",
    "        Args:\n",
    "            pose (Pose): The pose to move.\n",
    "            xyz (tuple): The cartesian 3D unit vector to move the pose in.\n",
    "\n",
    "        Returns:\n",
    "            pose (Pose): The moved pose.\n",
    "        \"\"\"    \n",
    "        from pyrosetta.rosetta.core.select.residue_selector import TrueResidueSelector\n",
    "        from pyrosetta.rosetta.protocols.toolbox.pose_manipulation import rigid_body_move\n",
    "        assert len(xyz) == 3\n",
    "        pose = pose.clone()\n",
    "        entire = TrueResidueSelector()\n",
    "        subset = entire.apply(pose)\n",
    "        # get which direction in cartesian unit vectors (xyz) to yeet pose\n",
    "        unit = pyrosetta.rosetta.numeric.xyzVector_double_t(*xyz)\n",
    "        scaled_xyz = tuple([100*x for x in xyz])\n",
    "        far_away = pyrosetta.rosetta.numeric.xyzVector_double_t(*scaled_xyz)\n",
    "        rigid_body_move(unit, 0, far_away, pose, subset)\n",
    "        return pose\n",
    "    \n",
    "    def combined_pose_maker(poses=[]) -> Pose:\n",
    "        \"\"\"\n",
    "        Combine up to 6 poses in a list into one multichain pose\n",
    "        \"\"\"\n",
    "        if len(poses) == 0:\n",
    "            raise RuntimeError(\"Empty list of poses passed\")\n",
    "        else:\n",
    "            pass\n",
    "        # get the first pose\n",
    "        new_pose = poses.pop(0).clone()\n",
    "        # unit vectors\n",
    "        xyzs = [(1,0,0),(0,1,0),(0,0,1),(-1,0,0),(0,-1,0),(0,0,-1)]\n",
    "        # go through rest of poses and add them into the first one\n",
    "        for i, pose in enumerate(poses):\n",
    "            xyz = xyzs[i]\n",
    "            to_append = yeet_pose_xyz(pose.clone(), xyz)\n",
    "            new_pose.append_pose_by_jump(\n",
    "                to_append,\n",
    "                new_pose.num_jump()+1, # last jump\n",
    "            )\n",
    "        return new_pose\n",
    "    \n",
    "    \n",
    "    def msd_fnr(despose, refpose, weight=0.0, strict_layers=False, neighbors=False, design_sel=None):\n",
    "        \"\"\"\n",
    "        Perform multi state design (MSD) using FavorNativeResidue (FNR)\n",
    "        \"\"\"\n",
    "        true_sel = pyrosetta.rosetta.core.select.residue_selector.TrueResidueSelector()\n",
    "        allres = pyrosetta.rosetta.core.select.get_residues_from_subset(true_sel.apply(despose))\n",
    "        diff = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "        # check each position for seq disagreement\n",
    "        for i in allres:\n",
    "            if despose.sequence(i,i) == \"C\": # maintain disulfides in despose\n",
    "                continue\n",
    "            elif refpose.sequence(i,i) == \"C\": # safely replace despose residue with CYS (not CYD)\n",
    "                mut = pyrosetta.rosetta.protocols.simple_moves.MutateResidue()\n",
    "                mut.set_target(i)\n",
    "                mut.set_res_name(pyrosetta.rosetta.core.chemical.AA(2)) # 2 is CYS\n",
    "                mut.apply(despose)\n",
    "            elif despose.sequence(i,i) != refpose.sequence(i,i):\n",
    "                diff.append(i)\n",
    "                despose.replace_residue(i,refpose.residue(i),1)\n",
    "            else:\n",
    "                pass\n",
    "        if design_sel is not None:\n",
    "            designable = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(design_sel)\n",
    "        else:\n",
    "            if neighbors: # design neighbors too\n",
    "                designable = pyrosetta.rosetta.core.select.residue_selector.NeighborhoodResidueSelector(\n",
    "                    pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(diff),\n",
    "                    6,\n",
    "                    True,\n",
    "                )\n",
    "            else: # design only diff\n",
    "                designable = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(diff)\n",
    "        packable = pyrosetta.rosetta.core.select.residue_selector.NeighborhoodResidueSelector(designable, 6, True)\n",
    "        pack_option = pyrosetta.rosetta.core.pack.task.operation.RestrictToRepackingRLT()\n",
    "        pack = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(pack_option, designable, True)\n",
    "        lock_option = pyrosetta.rosetta.core.pack.task.operation.PreventRepackingRLT()\n",
    "        lock = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(lock_option, packable, True)\n",
    "        # add standard task operations\n",
    "        arochi = pyrosetta.rosetta.protocols.task_operations.LimitAromaChi2Operation()\n",
    "        arochi.chi2max(110)\n",
    "        arochi.chi2min(70)\n",
    "        arochi.include_trp(True)\n",
    "        ifcl = pyrosetta.rosetta.core.pack.task.operation.InitializeFromCommandline()\n",
    "        # setup custom layer design\n",
    "        ss1 = pyrosetta.rosetta.core.scoring.dssp.Dssp(state_X)\n",
    "        ss2 = pyrosetta.rosetta.core.scoring.dssp.Dssp(state_Y)\n",
    "        surf_sel = pyrosetta.rosetta.core.select.residue_selector.LayerSelector()\n",
    "        surf_sel.set_layers(0,0,1)\n",
    "        surf_sel.set_use_sc_neighbors(0)\n",
    "        surf_sel.set_cutoffs(20,50)\n",
    "        surf1 = pyrosetta.rosetta.core.select.get_residues_from_subset(surf_sel.apply(state_X))\n",
    "        surf2 = pyrosetta.rosetta.core.select.get_residues_from_subset(surf_sel.apply(state_Y))\n",
    "        core_sel = pyrosetta.rosetta.core.select.residue_selector.LayerSelector()\n",
    "        core_sel.set_layers(1,0,0)\n",
    "        core_sel.set_use_sc_neighbors(0)\n",
    "        core1 = pyrosetta.rosetta.core.select.get_residues_from_subset(core_sel.apply(state_X))\n",
    "        core2 = pyrosetta.rosetta.core.select.get_residues_from_subset(core_sel.apply(state_Y))\n",
    "        core_both = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "        surf_both = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "        bdry_core = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "        bdry_surf = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "        surf_core = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "        bdry_both = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "        for i in allres:\n",
    "            if i in core1:\n",
    "                if i in core2:\n",
    "                    core_both.append(i)\n",
    "                elif i in surf2:\n",
    "                    surf_core.append(i)\n",
    "                else:\n",
    "                    bdry_core.append(i)\n",
    "            elif i in surf1:\n",
    "                if i in surf2:\n",
    "                    surf_both.append(i)\n",
    "                elif i in core2:\n",
    "                    surf_core.append(i)\n",
    "                else:\n",
    "                    bdry_surf.append(i)\n",
    "            else:\n",
    "                if i in core2:\n",
    "                    bdry_core.append(i)\n",
    "                elif i in surf2:\n",
    "                    bdry_surf.append(i)\n",
    "                else:\n",
    "                    bdry_both.append(i)\n",
    "        if len(core_both) > 0:\n",
    "            sel_core_both = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(core_both)\n",
    "        else:\n",
    "            sel_core_both = pyrosetta.rosetta.core.select.residue_selector.FalseResidueSelector()\n",
    "        sel_surf_both = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(surf_both)\n",
    "        if len(bdry_core) > 0:\n",
    "            sel_bdry_core = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(bdry_core)\n",
    "        else:\n",
    "            sel_bdry_core = pyrosetta.rosetta.core.select.residue_selector.FalseResidueSelector()\n",
    "        if len(bdry_surf) > 0:\n",
    "            sel_bdry_surf = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(bdry_surf)\n",
    "        else:\n",
    "            sel_bdry_surf = pyrosetta.rosetta.core.select.residue_selector.FalseResidueSelector()\n",
    "        if len(surf_core) > 0:\n",
    "            sel_surf_core = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(surf_core)\n",
    "        else:\n",
    "            sel_surf_core = pyrosetta.rosetta.core.select.residue_selector.FalseResidueSelector()\n",
    "        sel_bdry_both = pyrosetta.rosetta.core.select.residue_selector.ResidueIndexSelector(bdry_both)\n",
    "        if strict_layers:\n",
    "            sel_c = pyrosetta.rosetta.core.select.residue_selector.OrResidueSelector(sel_core_both,sel_bdry_core)\n",
    "            sel_b = pyrosetta.rosetta.core.select.residue_selector.OrResidueSelector(sel_bdry_both,sel_surf_core)\n",
    "            sel_s = pyrosetta.rosetta.core.select.residue_selector.OrResidueSelector(sel_surf_both,sel_bdry_surf)\n",
    "        else:\n",
    "            sel_c = sel_core_both\n",
    "            sel_s = sel_surf_both\n",
    "            sel_c_or_s = pyrosetta.rosetta.core.select.residue_selector.OrResidueSelector(sel_core_both,sel_surf_both)\n",
    "            sel_b = pyrosetta.rosetta.core.select.residue_selector.NotResidueSelector(sel_c_or_s)\n",
    "\n",
    "        objs_sel = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\n",
    "            \"\"\"\n",
    "            <RESIDUE_SELECTORS>\n",
    "                <SecondaryStructure name=\"sheet\" overlap=\"0\" minH=\"3\" minE=\"2\" include_terminal_loops=\"false\" use_dssp=\"true\" ss=\"E\"/>\n",
    "                <SecondaryStructure name=\"entire_loop\" overlap=\"0\" minH=\"3\" minE=\"2\" include_terminal_loops=\"true\" use_dssp=\"true\" ss=\"L\"/>\n",
    "                <SecondaryStructure name=\"entire_helix\" overlap=\"0\" minH=\"3\" minE=\"2\" include_terminal_loops=\"false\" use_dssp=\"true\" ss=\"H\"/>\n",
    "                <And name=\"helix_cap\" selectors=\"entire_loop\">\n",
    "                    <PrimarySequenceNeighborhood lower=\"1\" upper=\"0\" selector=\"entire_helix\"/>\n",
    "                </And>\n",
    "                <And name=\"helix_start\" selectors=\"entire_helix\">\n",
    "                    <PrimarySequenceNeighborhood lower=\"0\" upper=\"1\" selector=\"helix_cap\"/>\n",
    "                </And>\n",
    "                <And name=\"helix\" selectors=\"entire_helix\">\n",
    "                    <Not selector=\"helix_start\"/>\n",
    "                </And>\n",
    "                <And name=\"loop\" selectors=\"entire_loop\">\n",
    "                    <Not selector=\"helix_cap\"/>\n",
    "                </And>\n",
    "            </RESIDUE_SELECTORS>\n",
    "            \"\"\"\n",
    "        )\n",
    "        helix_sel = objs_sel.get_residue_selector(\"helix\")\n",
    "        loop_sel = objs_sel.get_residue_selector(\"loop\")\n",
    "        helix_cap_sel = objs_sel.get_residue_selector(\"helix_cap\")\n",
    "\n",
    "        core_hlx_sel = pyrosetta.rosetta.core.select.residue_selector.AndResidueSelector(sel_c,helix_sel)\n",
    "        bdry_hlx_sel = pyrosetta.rosetta.core.select.residue_selector.AndResidueSelector(sel_b,helix_sel)\n",
    "        surf_hlx_sel = pyrosetta.rosetta.core.select.residue_selector.AndResidueSelector(sel_s,helix_sel)\n",
    "        core_loop_sel = pyrosetta.rosetta.core.select.residue_selector.AndResidueSelector(sel_c,loop_sel)\n",
    "        bdry_loop_sel = pyrosetta.rosetta.core.select.residue_selector.AndResidueSelector(sel_b,loop_sel)\n",
    "        surf_loop_sel = pyrosetta.rosetta.core.select.residue_selector.AndResidueSelector(sel_s,loop_sel)\n",
    "\n",
    "        # layer design task ops, allows the current residue at a given position if it is not included\n",
    "        core_hlx_task = pyrosetta.rosetta.core.pack.task.operation.RestrictAbsentCanonicalAASExceptNativeRLT()\n",
    "        core_hlx_task.aas_to_keep(\"AFILVW\")\n",
    "        bdry_hlx_task = pyrosetta.rosetta.core.pack.task.operation.RestrictAbsentCanonicalAASExceptNativeRLT()\n",
    "        bdry_hlx_task.aas_to_keep(\"ADEHIKLNQRSTVWYM\")\n",
    "        surf_hlx_task = pyrosetta.rosetta.core.pack.task.operation.RestrictAbsentCanonicalAASExceptNativeRLT()\n",
    "        surf_hlx_task.aas_to_keep(\"EHKQR\")\n",
    "        core_loop_task = pyrosetta.rosetta.core.pack.task.operation.RestrictAbsentCanonicalAASExceptNativeRLT()\n",
    "        core_loop_task.aas_to_keep(\"AFGILPVW\")\n",
    "        bdry_loop_task = pyrosetta.rosetta.core.pack.task.operation.RestrictAbsentCanonicalAASExceptNativeRLT()\n",
    "        bdry_loop_task.aas_to_keep(\"ADEFGHIKLNPQRSTVWY\")\n",
    "        surf_loop_task = pyrosetta.rosetta.core.pack.task.operation.RestrictAbsentCanonicalAASExceptNativeRLT()\n",
    "        surf_loop_task.aas_to_keep(\"DEGHKNPQRST\")\n",
    "        hlx_cap_task = pyrosetta.rosetta.core.pack.task.operation.RestrictAbsentCanonicalAASExceptNativeRLT()\n",
    "        hlx_cap_task.aas_to_keep(\"DNSTP\")\n",
    "\n",
    "        hlx_cap_op   = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(hlx_cap_task  , helix_cap_sel, False)\n",
    "        core_hlx_op  = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(core_hlx_task , core_hlx_sel , False)\n",
    "        bdry_hlx_op  = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(bdry_hlx_task , bdry_hlx_sel , False)\n",
    "        surf_hlx_op  = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(surf_hlx_task , surf_hlx_sel , False)\n",
    "        core_loop_op = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(core_loop_task, core_loop_sel, False)\n",
    "        bdry_loop_op = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(bdry_loop_task, bdry_loop_sel, False)\n",
    "        surf_loop_op = pyrosetta.rosetta.core.pack.task.operation.OperateOnResidueSubset(surf_loop_task, surf_loop_sel, False)\n",
    "\n",
    "        # push back all task ops, assumes no sheets\n",
    "        task_factory = pyrosetta.rosetta.core.pack.task.TaskFactory()\n",
    "        task_factory.push_back(pack)\n",
    "        task_factory.push_back(lock)\n",
    "        task_factory.push_back(arochi)\n",
    "        task_factory.push_back(ifcl)\n",
    "        task_factory.push_back(hlx_cap_op)\n",
    "        task_factory.push_back(core_hlx_op)\n",
    "        task_factory.push_back(bdry_hlx_op)\n",
    "        task_factory.push_back(surf_hlx_op)\n",
    "        task_factory.push_back(core_loop_op)\n",
    "        task_factory.push_back(bdry_loop_op)\n",
    "        task_factory.push_back(surf_loop_op)\n",
    "\n",
    "        # add design movers\n",
    "        objs = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\n",
    "            \"\"\"\n",
    "            <MOVERS>\n",
    "            <FastDesign name=\"fastdesign\" repeats=\"1\" relaxscript=\"MonomerDesign2019\"\n",
    "                cartesian=\"false\" dualspace=\"false\" ramp_down_constraints=\"false\"\n",
    "                bondangle=\"false\" bondlength=\"false\" min_type=\"lbfgs_armijo_nonmonotone\">\n",
    "            </FastDesign>\n",
    "            <AddSapConstraintMover name=\"add_sap\" speed=\"lightning\" sap_goal=\"0\" penalty_per_sap=\"{np_penalty}\" />\n",
    "            <AddCompositionConstraintMover name=\"ala_pen\" >\n",
    "                <Comp entry=\"PENALTY_DEFINITION;TYPE ALA;ABSOLUTE 0;PENALTIES 0 {ala_penalty};DELTA_START 0;DELTA_END 1;BEFORE_FUNCTION CONSTANT;AFTER_FUNCTION LINEAR;END_PENALTY_DEFINITION;\" />\n",
    "            </AddCompositionConstraintMover>\n",
    "            </MOVERS>\n",
    "            \"\"\".format(np_penalty=np_penalty, ala_penalty=ala_penalty)) \n",
    "        surfpol = objs.get_mover(\"add_sap\")\n",
    "        surfpol.apply(despose)\n",
    "        ala_pen = objs.get_mover(\"ala_pen\")\n",
    "        ala_pen.apply(despose)\n",
    "        fast_design = objs.get_mover(\"fastdesign\")\n",
    "        fast_design.set_scorefxn(sfxn)\n",
    "        fast_design.set_task_factory(task_factory)\n",
    "        # skip design if sequences have already converged\n",
    "        if len(diff) > 0:\n",
    "            pyrosetta.rosetta.protocols.protein_interface_design.FavorNativeResidue(despose, weight)\n",
    "            fast_design.apply(despose)\n",
    "        # remove constraints\n",
    "        clear_constraints = pyrosetta.rosetta.protocols.constraint_movers.ClearConstraintsMover()\n",
    "        clear_constraints.apply(despose)\n",
    "        return\n",
    "\n",
    "    # recover original interfacial residues and combine those from each state, assumes middle split\n",
    "    objs_sse = pyrosetta.rosetta.protocols.rosetta_scripts.XmlObjects.create_from_string(\n",
    "        \"\"\"\n",
    "        <RESIDUE_SELECTORS>\n",
    "            <SSElement name=\"part1\" selection=\"n_term\" to_selection=\"{pre},H,E\" chain=\"A\" reassign_short_terminal_loop=\"2\" />\n",
    "            <SSElement name=\"part2\" selection=\"-{post},H,S\" to_selection=\"c_term\" chain=\"A\" reassign_short_terminal_loop=\"2\" />\n",
    "        </RESIDUE_SELECTORS>\n",
    "        \"\"\".format(\n",
    "            pre = int(scores[\"pre_break_helix\"]),\n",
    "            post = int(scores[\"pre_break_helix\"]),\n",
    "        )\n",
    "    )\n",
    "    part1 = objs_sse.get_residue_selector(\"part1\")\n",
    "    part2 = objs_sse.get_residue_selector(\"part2\")\n",
    "    intsel = pyrosetta.rosetta.core.select.residue_selector.InterGroupInterfaceByVectorSelector(part1,part2)\n",
    "    intdes = pyrosetta.rosetta.core.select.get_residues_from_subset(intsel.apply(state_Y))\n",
    "    intref = pyrosetta.rosetta.core.select.get_residues_from_subset(intsel.apply(state_X))\n",
    "    intall = pyrosetta.rosetta.utility.vector1_unsigned_long()\n",
    "    # add all residues in either interface to be designed\n",
    "    for i in intdes:\n",
    "        intall.append(i)\n",
    "    for i in intref:\n",
    "        intall.append(i)\n",
    "    # one round msd with no weight, lenient layers, no neighbors on all residues that are interface in either state\n",
    "    msd_fnr(despose=state_Y, refpose=state_X, weight=0, strict_layers=False, neighbors=False, design_sel=intall)\n",
    "    # one round msd with no weight, strict layers, and neighbors on all residues that are different between states\n",
    "    msd_fnr(despose=state_X, refpose=state_Y, weight=0, strict_layers=True, neighbors=True)\n",
    "    # one round msd with no weight, strict layers, no neighbors on all residues that are different between states\n",
    "    msd_fnr(despose=state_Y, refpose=state_X, weight=0, strict_layers=True)\n",
    "    # two rounds, ramp weight with strict layers, no neighbors on all residues that are different between states\n",
    "    for wt in [0.2, 0.5, 1.0]:\n",
    "        msd_fnr(despose=state_X, refpose=state_Y, weight=wt, strict_layers=True)\n",
    "        msd_fnr(despose=state_Y, refpose=state_X, weight=wt, strict_layers=True)\n",
    "    # two rounds, ramp weight with lenient layers, no neighbors on all residues that are different between states\n",
    "    for wt in [1.5, 2.0]:\n",
    "        msd_fnr(despose=state_X, refpose=state_Y, weight=wt, strict_layers=False)\n",
    "        msd_fnr(despose=state_Y, refpose=state_X, weight=wt, strict_layers=False)\n",
    "    # set SAP penalty to 1 and alanine penalty for 0 for the last rounds\n",
    "    np_penalty = 1; ala_penalty = 0; wt = 10\n",
    "    # two rounds, max weight with lenient layers, no neighbors on all residues that are different between states\n",
    "    msd_fnr(despose=state_X, refpose=state_Y, weight=wt, strict_layers=False)\n",
    "    msd_fnr(despose=state_Y, refpose=state_X, weight=wt, strict_layers=False)\n",
    "    # if sequences fail to converge, report failure and do not yield combined pose \n",
    "    try:\n",
    "        assert state_X.sequence() == state_Y.sequence()\n",
    "    except AssertionError:\n",
    "        print(\"Convergence failure with the following sequences:\")\n",
    "        print(\"X:\", state_X.sequence())\n",
    "        print(\"Y:\", state_Y.sequence())\n",
    "        return\n",
    "    to_return = [state_X, state_Y]\n",
    "    scores_X = deepcopy(state_X.scores)\n",
    "    scores_Y = deepcopy(state_Y.scores)\n",
    "    combined_scores = {}\n",
    "    combined_scores[\"abegos_X\"] = scores_X[\"abego_str\"]\n",
    "    combined_scores[\"abegos_Y\"] = scores_Y[\"abego_str\"]\n",
    "    combined_scores[\"dssp_X\"] = scores_X[\"dssp\"]\n",
    "    combined_scores[\"dssp_Y\"] = scores_Y[\"dssp\"]\n",
    "    combined_scores[\"closure_type_X\"] = scores_X[\"closure_type\"]\n",
    "    combined_scores[\"closure_type_Y\"] = scores_Y[\"closure_type\"]\n",
    "    combined_scores[\"disulfide_at_X\"] = scores_X[\"disulfide_at\"]\n",
    "    combined_scores[\"disulfide_at_Y\"] = scores_Y[\"disulfide_at\"]\n",
    "    combined_scores[\"score_per_res_pre_X\"] = score_per_res_X\n",
    "    combined_scores[\"score_per_res_pre_Y\"] = score_per_res_Y\n",
    "    combined_scores[\"dslf_fa13_cart_X\"] = scores_X[\"dslf_fa13_cart\"]\n",
    "    combined_scores[\"dslf_fa13_cart_Y\"] = scores_Y[\"dslf_fa13_cart\"]\n",
    "    combined_scores[\"rmsd_cart_X\"] = scores_X[\"rmsd_cart\"]\n",
    "    combined_scores[\"rmsd_cart_Y\"] = scores_Y[\"rmsd_cart\"]\n",
    "    common_keys = [\n",
    "        \"new_loop_resis\",\n",
    "        \"parent\",\n",
    "        \"scaffold\",\n",
    "        \"sfxn_used\",\n",
    "        \"state\",\n",
    "        \"bb_clash\",\n",
    "        \"nmodes_attempts\",\n",
    "        \"pivot_helix\",\n",
    "        \"pre_break_helix\",\n",
    "        \"shift\",\n",
    "        \"total_length\",\n",
    "    ]\n",
    "    for common_key in common_keys:\n",
    "        combined_scores[common_key] = scores_Y[common_key]\n",
    "    combined_XY = combined_pose_maker(poses)\n",
    "    # clear scores and update\n",
    "    pyrosetta.rosetta.core.pose.clearPoseExtraScores(combined_XY)\n",
    "    for key, value in combined_scores.items():\n",
    "        pyrosetta.rosetta.core.pose.setPoseExtraScore(combined_XY, key, value)\n",
    "    pyrosetta.rosetta.core.pose.setPoseExtraScore(combined_XY, \"sequence\", state_Y.sequence())\n",
    "    pyrosetta.rosetta.core.pose.setPoseExtraScore(combined_XY, \"parent_sequence\", parent_sequence)\n",
    "    pyrosetta.rosetta.core.pose.setPoseExtraScore(combined_XY, \"np_penalty\", og_np_penalty)\n",
    "    combined_XY = io.to_packed(combined_XY)\n",
    "    yield combined_XY\n",
    "\n",
    "def score(ppose: PackedPose, **kwargs) -> PackedPose:\n",
    "    \"\"\"\n",
    "    Individually score each state of the combined state_X, state_Y pose passed. \n",
    "    Return the pose containing scores for each state and chain A = X; B = Y\n",
    "    TODO, better dict update\n",
    "    \"\"\"\n",
    "    from copy import deepcopy\n",
    "    import pyrosetta\n",
    "    import pyrosetta.distributed.io as io\n",
    "    from pyrosetta.distributed.tasks.rosetta_scripts import SingleoutputRosettaScriptsTask\n",
    "    \n",
    "    original_scores = deepcopy(ppose.pose.scores)\n",
    "    pose = ppose.pose.clone()\n",
    "    # clean pose\n",
    "    for key, _ in original_scores.items():\n",
    "        pyrosetta.rosetta.core.pose.clearPoseExtraScore(pose, key)\n",
    "        \n",
    "    sfxn = original_scores[\"sfxn_used\"]\n",
    "    new_loop_resis = original_scores[\"new_loop_resis\"]\n",
    "    \n",
    "    score_dicts = []\n",
    "    chains_to_delete = (\"X\", \"delete_Y\"), (\"Y\", \"delete_X\")\n",
    "    for chain, chain_to_delete in chains_to_delete:\n",
    "    \n",
    "        xml = \"\"\"\n",
    "        <ROSETTASCRIPTS>\n",
    "            <SCOREFXNS>\n",
    "                <ScoreFunction name=\"sfxn\" weights=\"{sfxn}\" />\n",
    "                <ScoreFunction name=\"sfxn_design\" weights=\"{sfxn}_cart\" >\n",
    "                    <Set use_hb_env_dep=\"true\" />\n",
    "                    <Reweight scoretype=\"approximate_buried_unsat_penalty\" weight=\"17\" />\n",
    "                    <Set approximate_buried_unsat_penalty_burial_atomic_depth=\"3.5\" />\n",
    "                    <Set approximate_buried_unsat_penalty_hbond_energy_threshold=\"-1.0\" />\n",
    "                    <Set approximate_buried_unsat_penalty_natural_corrections1=\"true\" />\n",
    "                    <Set approximate_buried_unsat_penalty_hbond_bonus_cross_chain=\"-7\" />\n",
    "                    <Set approximate_buried_unsat_penalty_hbond_bonus_ser_to_helix_bb=\"1\"/>                    \n",
    "                </ScoreFunction>\n",
    "            </SCOREFXNS>\n",
    "            <RESIDUE_SELECTORS>\n",
    "                <Index name=\"new_loop_resis\" resnums=\"{new_loop_resis}\" />\n",
    "                <Neighborhood name=\"around_new_loop\" selector=\"new_loop_resis\" distance=\"8.0\" />\n",
    "            </RESIDUE_SELECTORS>\n",
    "            <TASKOPERATIONS>\n",
    "                <IncludeCurrent name=\"current\" />\n",
    "                <LimitAromaChi2 name=\"arochi\" chi2max=\"110\" chi2min=\"70\" include_trp=\"True\" />\n",
    "                <ExtraRotamersGeneric name=\"ex1_ex2\" ex1=\"1\" ex2=\"1\" />\n",
    "                <InitializeFromCommandline name=\"ifcl\"/>\n",
    "            </TASKOPERATIONS>\n",
    "            <MOVERS>\n",
    "                <SavePoseMover name=\"save_before_relax\" restore_pose=\"0\" reference_name=\"before_relax\"/>\n",
    "                <SwitchChainOrder name=\"delete_Y\" chain_order=\"1\"/>\n",
    "                <SwitchChainOrder name=\"delete_X\" chain_order=\"2\"/>\n",
    "            </MOVERS>\n",
    "            <FILTERS>\n",
    "                <BuriedUnsatHbonds name=\"vbuns\" use_reporter_behavior=\"true\" report_all_heavy_atom_unsats=\"true\" \n",
    "                    scorefxn=\"sfxn\" ignore_surface_res=\"false\" print_out_info_to_pdb=\"true\" confidence=\"0\" \n",
    "                    use_ddG_style=\"false\" dalphaball_sasa=\"true\" probe_radius=\"1.1\" atomic_depth_selection=\"5.5\" \n",
    "                    burial_cutoff=\"1000\" burial_cutoff_apo=\"0.2\" />\n",
    "                <BuriedUnsatHbonds name=\"sbuns\" use_reporter_behavior=\"true\" report_all_heavy_atom_unsats=\"true\"\n",
    "                    scorefxn=\"sfxn\" ignore_surface_res=\"false\" print_out_info_to_pdb=\"true\" confidence=\"0\"\n",
    "                    use_ddG_style=\"false\" burial_cutoff=\"0.01\" dalphaball_sasa=\"true\" probe_radius=\"1.1\" \n",
    "                    atomic_depth_selection=\"5.5\" atomic_depth_deeper_than=\"false\" />\n",
    "                <BuriedUnsatHbonds name=\"buns\" use_reporter_behavior=\"true\" report_all_heavy_atom_unsats=\"true\" \n",
    "                    scorefxn=\"sfxn\" ignore_surface_res=\"false\" print_out_info_to_pdb=\"true\" confidence=\"0\" \n",
    "                    use_ddG_style=\"false\" burial_cutoff=\"0.01\" dalphaball_sasa=\"true\" probe_radius=\"1.1\"\n",
    "                    max_hbond_energy=\"1.5\" burial_cutoff_apo=\"0.2\" />\n",
    "                <ExposedHydrophobics name=\"exposed_hydrophobics\" />\n",
    "                <Geometry name=\"geometry\"\n",
    "                    confidence=\"0\"\n",
    "                    count_bad_residues=\"true\" />\n",
    "                <Geometry name=\"geometry_loop\" \n",
    "                    residue_selector=\"around_new_loop\" \n",
    "                    confidence=\"0\"\n",
    "                    count_bad_residues=\"true\" />\n",
    "                <SSPrediction name=\"mismatch_probability\" confidence=\"0\" \n",
    "                    cmd=\"/software/psipred4/runpsipred_single\" use_probability=\"1\" \n",
    "                    mismatch_probability=\"1\" use_svm=\"1\" />\n",
    "                <Rmsd name=\"rmsd_cart_final\" reference_name=\"before_relax\" chains=\"A\" superimpose=\"1\" threshold=\"5\" by_aln=\"0\" confidence=\"0\" />\n",
    "                <ScoreType name=\"total_score_pose\" scorefxn=\"sfxn\" score_type=\"total_score\" threshold=\"0\" confidence=\"0\" />\n",
    "                <ResidueCount name=\"count\" />\n",
    "                <CalculatorFilter name=\"score_per_res\" equation=\"total_score_full / res\" threshold=\"-2.0\" confidence=\"0\">\n",
    "                    <Var name=\"total_score_full\" filter=\"total_score_pose\"/>\n",
    "                    <Var name=\"res\" filter=\"count\"/>\n",
    "                </CalculatorFilter>        \n",
    "                <worst9mer name=\"wnm_all\" rmsd_lookup_threshold=\"0.4\" confidence=\"0\" />\n",
    "                <worst9mer name=\"wnm_hlx\" rmsd_lookup_threshold=\"0.4\" confidence=\"0\" only_helices=\"true\" />\n",
    "\n",
    "            </FILTERS>\n",
    "            <MOVERS>\n",
    "                <FastRelax name=\"relax_cart\" scorefxn=\"sfxn_design\" repeats=\"1\" batch=\"false\" ramp_down_constraints=\"false\"\n",
    "                    cartesian=\"true\" bondangle=\"true\" bondlength=\"true\" min_type=\"dfpmin_armijo_nonmonotone\"\n",
    "                    task_operations=\"ifcl,current,arochi,ex1_ex2\" >\n",
    "                </FastRelax>\n",
    "            </MOVERS>\n",
    "            <SIMPLE_METRICS>\n",
    "                <SapScoreMetric name=\"sap_score\" />\n",
    "            </SIMPLE_METRICS>\n",
    "            <APPLY_TO_POSE>\n",
    "            </APPLY_TO_POSE>\n",
    "            <PROTOCOLS>\n",
    "                <Add mover_name=\"{chain_to_delete}\" />\n",
    "                <Add mover_name=\"save_before_relax\" />\n",
    "                <Add mover_name=\"relax_cart\"/>\n",
    "                <Add filter_name=\"buns\" />\n",
    "                <Add filter_name=\"sbuns\" />\n",
    "                <Add filter_name=\"vbuns\" />\n",
    "                <Add filter_name=\"exposed_hydrophobics\" />\n",
    "                <Add filter_name=\"geometry\"/>\n",
    "                <Add filter_name=\"geometry_loop\"/>\n",
    "                <Add filter_name=\"mismatch_probability\" />\n",
    "                <Add filter_name=\"rmsd_cart_final\" />\n",
    "                <Add metrics=\"sap_score\" />\n",
    "                <Add filter_name=\"score_per_res\" />\n",
    "                <Add filter_name=\"wnm_all\" />\n",
    "                <Add filter_name=\"wnm_hlx\" />\n",
    "\n",
    "            </PROTOCOLS>\n",
    "            <OUTPUT scorefxn=\"sfxn\" />\n",
    "        </ROSETTASCRIPTS>\n",
    "        \"\"\".format(\n",
    "            sfxn=sfxn,\n",
    "            new_loop_resis=new_loop_resis,\n",
    "            chain_to_delete=chain_to_delete,\n",
    "        )\n",
    "        scored = SingleoutputRosettaScriptsTask(xml)\n",
    "        scored_ppose = scored(pose.clone())\n",
    "        pose_scores = deepcopy(scored_ppose.pose.scores)\n",
    "        pose_scores = {f\"{key}_{chain}\": value for key, value in pose_scores.items()}\n",
    "        score_dicts.append(pose_scores)\n",
    "    \n",
    "    # fancy dictionary update not ready until python 3.9 sadly; would look like dict0 | dict1\n",
    "    scores = {**score_dicts[0], **score_dicts[1]}\n",
    "    scores.update(original_scores)\n",
    "    for key, value in scores.items():\n",
    "        pyrosetta.rosetta.core.pose.setPoseExtraScore(pose, key, value)\n",
    "    scored_ppose = io.to_packed(pose)\n",
    "    return scored_ppose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Dask\n",
    "Trying a adaptive SLURMCluster. to see the dashboard, forward port `8787` to `8000`:  \n",
    "`local$ ssh -L 8000:localhost:8787 $USER@$HOSTNAME`  \n",
    "now, the web UI is visible at `localhost:8000`  \n",
    "if you\"re using a local cluster make sure the node this notebook is on has the same \n",
    "number of workers as cores\n",
    "\n",
    "TODO, force stdout to go into logs\n",
    "TODO `extra=[\"--lifetime\", \"170m\", \"--lifetime-stagger\", \"4m\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dig105\n",
      "pleung\n"
     ]
    }
   ],
   "source": [
    "!echo $HOSTNAME\n",
    "!echo $USER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    cores=1,\n",
    "    processes=1,\n",
    "    job_cpu=1,\n",
    "    local_directory=\"$TMPDIR/dask\",\n",
    "    log_directory=\"/mnt/home/pleung/logs/slurm_logs\",\n",
    "    memory=\"2.8GB\",\n",
    "    queue=\"medium\",\n",
    "    walltime=\"23:58:00\",\n",
    "    death_timeout=600,\n",
    ")\n",
    "print(cluster.job_script())\n",
    "# scale between 0 and 1000 workers as needed\n",
    "cluster.adapt(minimum=0, maximum=1000, wait_count=999) \n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.close(); cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set command line options, make tasks and submit to client\n",
    "Try `nstruct` of 40 to start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pyrosetta.distributed.io as io\n",
    "from pyrosetta.distributed.cluster.core import PyRosettaCluster\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "import random\n",
    "\n",
    "pickles = glob(os.path.join(os.getcwd(), \"04_pickles/DHR*/*.pickle\"))\n",
    "more_pickles = glob(os.path.join(os.getcwd(), \"04_pickles/hDHR*/*.pickle\"))\n",
    "pickles.extend(more_pickles)\n",
    "\n",
    "options = { \n",
    "    \"-out:level\": \"300\",\n",
    "    \"-holes:dalphaball\": \"/home/bcov/ppi/tutorial_build/main/source/external/DAlpahBall/DAlphaBall.gcc\",\n",
    "    \"-indexed_structure_store:fragment_store\": \"/net/databases/VALL_clustered/connect_chains/ss_grouped_vall_helix_shortLoop.h5\",\n",
    "    \"-dunbrack_prob_buried\": \"0.8\",\n",
    "    \"-dunbrack_prob_nonburied\": \"0.8\", \n",
    "    \"-dunbrack_prob_buried_semi\": \"0.8\", \n",
    "    \"-dunbrack_prob_nonburied_semi\": \"0.8\",\n",
    "}\n",
    "\n",
    "def create_tasks(pickles, options):\n",
    "    for pickle_path in pickles:\n",
    "        tasks = {\"options\": \"-corrections::beta_nov16 true\"}\n",
    "        tasks[\"extra_options\"] = options\n",
    "        tasks[\"pickle_path\"] = pickle_path\n",
    "        tasks[\"np_pen\"] = 2\n",
    "        tasks[\"set_logging_handler\"] = \"interactive\"\n",
    "        yield tasks\n",
    "        \n",
    "if not os.getenv(\"DEBUG\"):\n",
    "    output_path = os.path.join(os.getcwd(), \"05_msd_score_att_0\")\n",
    "    PyRosettaCluster(\n",
    "        tasks=create_tasks(pickles, options),\n",
    "        client=client,\n",
    "        scratch_dir=output_path,\n",
    "        output_path=output_path,\n",
    "        nstruct=40,\n",
    "    ).distribute(protocols=[msd, score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close(), cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at scores\n",
    "There is certainly a less embarrassing way to do this but at least this way is vectorized, so it should scale very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scorefile(scores):\n",
    "    import pandas as pd\n",
    "    scores = pd.read_json(scores, orient=\"records\", typ=\"frame\", lines=True)\n",
    "    scores = scores.T\n",
    "    mat = scores.values\n",
    "    n = mat.shape[0]\n",
    "    dicts = list(mat[range(n), range(n)])\n",
    "    index = scores.index\n",
    "    tabulated_scores = pd.DataFrame(dicts, index=index)\n",
    "    return tabulated_scores\n",
    "    \n",
    "output_path = os.path.join(os.getcwd(), \"05_two_state_n1_sap\")\n",
    "scores = os.path.join(output_path, \"scores.json\")\n",
    "scores_df = read_scorefile(scores)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # TODO add scoreterm denoting whether parent is ref or state 0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(scores_df))\n",
    "print(list(scores_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(\n",
    "    context=\"talk\",\n",
    "    font_scale=2, # make the font larger; default is pretty small\n",
    "    style=\"ticks\", # make the background white with black lines\n",
    "    palette=\"colorblind\" # a color palette that is colorblind friendly!\n",
    ")\n",
    "\n",
    "sap_subset = scores_df[\n",
    "    [\n",
    "        \"sap_score_X\",\n",
    "        \"sap_score_Y\",\n",
    "        \"parent\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, hue=\"parent\", corner=True, height=8)\n",
    "plt.suptitle(\"Correlation of SAP, split by parent\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_sap_split_by_parent.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho(x, y, ax=None, **kwargs):\n",
    "    \"\"\"Plot the correlation coefficient in the top left hand corner of a plot.\n",
    "    https://stackoverflow.com/questions/50832204/show-correlation-values-in-pairplot-using-seaborn-in-python/50835066\n",
    "    \"\"\"\n",
    "    import scipy\n",
    "    r, _ = scipy.stats.pearsonr(x, y)\n",
    "    ax = ax or plt.gca()\n",
    "    # Unicode for lowercase rho (ρ) \n",
    "    rho = \"\\u03C1\"\n",
    "    ax.annotate(f\"{rho} = {r:.2f}\", xy=(.1, .9), xycoords=ax.transAxes)\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, corner=True, height=8)\n",
    "ax.map_lower(rho)\n",
    "plt.suptitle(\"Correlation of SAP, with pearson R\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_SAP_pearson.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sap_subset = scores_df[\n",
    "    [\n",
    "        \"exposed_hydrophobics_X\",\n",
    "        \"exposed_hydrophobics_Y\",\n",
    "        \"sap_score_X\",\n",
    "        \"sap_score_Y\",\n",
    "        \"parent\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, hue=\"parent\", corner=True, height=8)\n",
    "plt.suptitle(\"Correlation of hydrophobicity, split by parent\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_hydrophobicity_split_by_parent.png\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, corner=True, height=8)\n",
    "ax.map_lower(rho)\n",
    "plt.suptitle(\"Correlation of hydrophobicity, with pearson R\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_hydrophobicity_pearson.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_subset = scores_df[\n",
    "    [\n",
    "        \"geometry_X\",\n",
    "        \"geometry_Y\",\n",
    "        \"mismatch_probability_X\",\n",
    "        \"mismatch_probability_Y\",\n",
    "        \"wnm_all_X\",\n",
    "        \"wnm_all_Y\",\n",
    "        \"wnm_hlx_X\",\n",
    "        \"wnm_hlx_Y\",\n",
    "        \"parent\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "ax = sns.pairplot(data=frag_subset, hue=\"parent\", corner=True, height=8)\n",
    "plt.suptitle(\"Correlation of fragment metrics, split by parent\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_frag_split_by_parent.png\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "ax = sns.pairplot(data=frag_subset, corner=True, height=8)\n",
    "ax.map_lower(rho)\n",
    "plt.suptitle(\"Correlation of fragment metrics, with pearson R\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_frag_pearson.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.getcwd(), \"05_two_state_n2_sap\")\n",
    "scores = os.path.join(output_path, \"scores.json\")\n",
    "scores_df = read_scorefile(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sap_subset = scores_df[\n",
    "    [\n",
    "        \"exposed_hydrophobics_X\",\n",
    "        \"exposed_hydrophobics_Y\",\n",
    "        \"np_penalty\",\n",
    "        \"sap_score_X\",\n",
    "        \"sap_score_Y\",\n",
    "        \"score_per_res_X\",\n",
    "        \"score_per_res_Y\",\n",
    "        \"parent\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, hue=\"parent\", corner=True, height=8)\n",
    "plt.suptitle(\"Correlation of hydrophobicity vs penalty, split by parent\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_hydrophobicity_penalty_split_by_parent.png\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, corner=True, height=8)\n",
    "ax.map_lower(rho)\n",
    "plt.suptitle(\"Correlation of hydrophobicity vs penalty, with pearson R\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_hydrophobicity_penalty_pearson.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.getcwd(), \"05_two_state_n500_sap\")\n",
    "scores = os.path.join(output_path, \"scores.json\")\n",
    "scores_df = read_scorefile(scores)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(scores_df.state.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in set(scores_df.state.values):\n",
    "    print(len(set(scores_df[scores_df[\"state\"] == state].sequence.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sap_subset = scores_df[\n",
    "    [\n",
    "        \"exposed_hydrophobics_X\",\n",
    "        \"exposed_hydrophobics_Y\",\n",
    "        \"sap_score_X\",\n",
    "        \"sap_score_Y\",\n",
    "        \"score_per_res_X\",\n",
    "        \"score_per_res_Y\",\n",
    "        \"parent\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, hue=\"parent\", corner=True, height=8)\n",
    "plt.suptitle(\"Correlation of hydrophobicity vs penalty, split by parent\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_n500_hydrophobicity_penalty_split_by_parent.png\")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "ax = sns.pairplot(data=sap_subset, corner=True, height=8)\n",
    "ax.map_lower(rho)\n",
    "plt.suptitle(\"Correlation of hydrophobicity vs penalty, with pearson R\")\n",
    "sns.despine()\n",
    "plt.savefig(\"figs/05_correlations_n500_hydrophobicity_penalty_pearson.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cereal",
   "language": "python",
   "name": "cereal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
